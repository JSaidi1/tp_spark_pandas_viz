{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b0a10b",
   "metadata": {},
   "source": [
    "# TP – Analyse de la qualité de l'air\n",
    "## Etape 1 – Exploration et chargement Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0196f0a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6153107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b07f55",
   "metadata": {},
   "source": [
    "### Créer une session Spark locale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f10634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ok]: Spark local session creation successful.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"TP - Analyse de la qualité de l'air - Etape 1: Exploration et chargement Spark\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "    print(f\"\\n[ok]: Spark local session creation successful.\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ko]: Spark local session creation failed: {e}\\n\")\n",
    "    sys.exit(1)\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\") # keep only error+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50be37a",
   "metadata": {},
   "source": [
    "### Charger `air_quality_raw.csv` en DataFrame Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f42dd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ok]: read source data file successfull: '../data/air_quality_raw.csv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_file_air_quality = \"../data/air_quality_raw.csv\"\n",
    "try:\n",
    "    df_air = spark.read \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"inferSchema\", \"true\") \\\n",
    "            .option(\"sep\", \",\") \\\n",
    "            .csv(data_file_air_quality)\n",
    "    print(f\"\\n[ok]: read source data file successfull: '{data_file_air_quality}'\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ko]: read source data file failed: {e}\\n\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe85f59",
   "metadata": {},
   "source": [
    "### Afficher le schéma inféré et identifier les problèmes de typage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88fdc420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- pollutant: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- unit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_air.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec5e5b6",
   "metadata": {},
   "source": [
    "Problèmes de typage:\n",
    "- timestamp: est en string => doit être en timestamp (TimestampType)\n",
    "- value: est en string => doit être en double (DoubleType)\n",
    "\n",
    "Solutions pour les problèmes de typages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64047bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## timestamp (parse them to yyyy-MM-dd HH:mm:ss):\n",
    "df_air = df_air.withColumn(\n",
    "    \"timestamp\",\n",
    "    F.coalesce(\n",
    "        F.to_timestamp(\"timestamp\", \"MM/dd/yyyy HH:mm:ss\"),   # e.g. 05/14/2024 04:00:00\n",
    "        F.to_timestamp(\"timestamp\", \"yyyy-MM-dd'T'HH:mm:ss\"), # e.g. 2024-06-05T01:00:00\n",
    "        F.to_timestamp(\"timestamp\", \"dd/MM/yyyy HH:mm\"),       # e.g. 18/03/2024 12:00\n",
    "        F.to_timestamp(\"timestamp\", \"yyyy-MM-dd HH:mm:ss\")    # e.g. 2024-05-23 11:00:00 (to keep the right format)\n",
    "    )\n",
    ")\n",
    "## value:\n",
    "df_air = df_air.withColumn(\n",
    "    \"value\",\n",
    "    F.regexp_replace(\"value\", \",\", \".\").cast(T.DoubleType())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b1646",
   "metadata": {},
   "source": [
    "### Nouveau schéma sans problèmes de typage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de754829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- pollutant: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- unit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_air.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516350bf",
   "metadata": {},
   "source": [
    "### Calculer des statistiques descriptives par polluant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f705ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------------------+------------------+-------+-------+\n",
      "|pollutant| count|              mean|            stddev|    min|    max|\n",
      "+---------+------+------------------+------------------+-------+-------+\n",
      "|     PM10|204133| 70.10033718213137|335.04846834319403|-132.57|4999.15|\n",
      "|      NO2|204093| 78.08748526407079|  336.511461014181|-163.48|4998.69|\n",
      "|       O3|204220|108.78000078346876| 337.0055311006316|-269.95|4999.37|\n",
      "|       CO|204062| 33.71101126128331|  341.164993171565|  -2.57|4996.48|\n",
      "|    PM2.5|204189| 55.31060331359669|336.76201626367117| -81.23|4999.69|\n",
      "|      SO2|204178|40.728096709733634|342.75159712088293| -26.57|4997.95|\n",
      "+---------+------+------------------+------------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Statistiques descriptives\n",
    "df_air.groupBy(\"pollutant\").agg(\n",
    "    F.count(\"value\").alias(\"count\"),\n",
    "    F.mean(\"value\").alias(\"mean\"),\n",
    "    F.stddev(\"value\").alias(\"stddev\"),\n",
    "    F.min(\"value\").alias(\"min\"),\n",
    "    F.max(\"value\").alias(\"max\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cce06c",
   "metadata": {},
   "source": [
    "### Compter les valeurs nulles par colonne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a50e0e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+-----+----+\n",
      "|station_id|timestamp|pollutant|value|unit|\n",
      "+----------+---------+---------+-----+----+\n",
      "|         0|        0|        0| 6076|   0|\n",
      "+----------+---------+---------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_air.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c)\n",
    "    for c in df_air.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be97108",
   "metadata": {},
   "source": [
    "### Identifier les stations avec le plus d'enregistrements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9848723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|station_id|count|\n",
      "+----------+-----+\n",
      "|    ST0032|26264|\n",
      "|    ST0012|26244|\n",
      "|    ST0028|26241|\n",
      "|    ST0003|26239|\n",
      "|    ST0029|26235|\n",
      "|    ST0024|26235|\n",
      "|    ST0020|26235|\n",
      "|    ST0037|26233|\n",
      "|    ST0023|26233|\n",
      "|    ST0042|26224|\n",
      "|    ST0015|26221|\n",
      "|    ST0035|26221|\n",
      "|    ST0007|26219|\n",
      "|    ST0044|26207|\n",
      "|    ST0030|26204|\n",
      "|    ST0017|26199|\n",
      "|    ST0014|26199|\n",
      "|    ST0010|26199|\n",
      "|    ST0009|26198|\n",
      "|    ST0040|26198|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gp_station = df_air.groupBy(\"station_id\").count().orderBy(F.desc(\"count\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a71e1",
   "metadata": {},
   "source": [
    "Les stations top 3 des stations avec le plus d'enregistrements: \n",
    "- La station **ST0032** avec 26264 enregistrement;\n",
    "- La station **ST0012** avec 26244 enregistrement;\n",
    "- La station **ST0028** avec 26241 enregistrement.\n",
    "\n",
    "*La station qui a le moins d'enregistrements est la ST0040 avec 26198 enregistrement.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d429e55",
   "metadata": {},
   "source": [
    "### Synthèse des problèmes de qualité identifiés:\n",
    "Problèmes de typage :\n",
    "- timestamp: est en string => doit être en timestamp (TimestampType) ==> pas de forme unique valide en spark\n",
    "- value: est en string => doit être en double (DoubleType) ==> pas de forme unique valide en spark (parfois des ,)\n",
    "\n",
    "Valeurs négatives dans la colonne value (des polluants), ce qui est pas logique ;\n",
    "Valeurs nulls également dans la colonne value (des polluants)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
